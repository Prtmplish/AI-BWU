{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'updated_placement_by_aptitude.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = ['Marks_sem1 ', 'Marks_sem2', 'Marks_sem3', 'Marks_sem4',\n",
    "                 'Marks_sem5', 'Marks_sem6', 'Marks_sem7', 'Marks_sem8', 'Soft_Skills_Score', 'Aptitude_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ML model\n",
    "X = df[new_features]\n",
    "\n",
    "# Handle any missing values (filling with mean for simplicity)\n",
    "X = X.fillna(X.median())\n",
    "# le = LabelEncoder()\n",
    "# y = le.fit_transform(df['Placement_domain'])\n",
    "'''le = LabelEncoder()'''\n",
    "y = df['Placement_domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust k_neighbors for SMOTE to be less than the number of minority samples (which is 5 for 'Advanced')\n",
    "smote = SMOTE(sampling_strategy='minority', k_neighbors=4)\n",
    "x_sm, y_sm = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_sm, y_sm, test_size=0.2, random_state=16, stratify=y_sm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "# Fix: Use target_names appropriate for the binary classification (Placement_domain)\n",
    "report = classification_report(y_test, pred, target_names=['Not Placed', 'Placed'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([[20, 70, 60, 70, 60, 65, 50, 45, 40, 68]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save model (pickle) ---\n",
    "with open('Interview_Preparedness.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = MLPClassifier(hidden_layer_sizes=(500, 100), max_iter=1000, activation = 'relu', solver = 'adam', batch_size = 32, learning_rate_init = 0.0001)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# pred = clf.predict(X_test)\n",
    "# report = classification_report(y_test, pred)\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import log_loss\n",
    "\n",
    "# def flatten_params(coefs, intercepts):\n",
    "#     return np.concatenate(\n",
    "#         [w.ravel() for w in coefs] +\n",
    "#         [b.ravel() for b in intercepts]\n",
    "#     )\n",
    "\n",
    "# def unflatten_params(flat, shapes):\n",
    "#     params = []\n",
    "#     idx = 0\n",
    "#     for shape in shapes:\n",
    "#         size = np.prod(shape)\n",
    "#         params.append(flat[idx:idx+size].reshape(shape))\n",
    "#         idx += size\n",
    "#     return params\n",
    "\n",
    "# original_params = flatten_params(clf.coefs_, clf.intercepts_)\n",
    "# shapes = [w.shape for w in clf.coefs_] + [b.shape for b in clf.intercepts_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "\n",
    "# d1 = np.random.randn(original_params.size)\n",
    "# d2 = np.random.randn(original_params.size)\n",
    "\n",
    "# d1 /= np.linalg.norm(d1)\n",
    "# d2 /= np.linalg.norm(d2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphas = np.linspace(-1, 1, 25)\n",
    "# betas = np.linspace(-1, 1, 25)\n",
    "\n",
    "# loss_surface = np.zeros((len(alphas), len(betas)))\n",
    "\n",
    "# for i, a in enumerate(alphas):\n",
    "#     for j, b in enumerate(betas):\n",
    "#         new_params = original_params + a * d1 + b * d2\n",
    "#         new_params_list = unflatten_params(new_params, shapes)\n",
    "\n",
    "#         # Assign perturbed parameters back to clf\n",
    "#         clf.coefs_ = new_params_list[:len(clf.coefs_)]\n",
    "#         clf.intercepts_ = new_params_list[len(clf.coefs_):]\n",
    "\n",
    "#         probs = clf.predict_proba(X)\n",
    "#         loss_surface[i, j] = log_loss(y, probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# A, B = np.meshgrid(alphas, betas)\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.contourf(A, B, loss_surface.T, levels=30)\n",
    "# plt.colorbar()\n",
    "# plt.xlabel(\"Direction 1\")\n",
    "# plt.ylabel(\"Direction 2\")\n",
    "# plt.title(\"Loss Surface Slice of sklearn MLPClassifier (clf)\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
