{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scikit-learn 1.4.0\n",
      "Uninstalling scikit-learn-1.4.0:\n",
      "  Successfully uninstalled scikit-learn-1.4.0\n",
      "Found existing installation: imbalanced-learn 0.14.1\n",
      "Uninstalling imbalanced-learn-0.14.1:\n",
      "  Successfully uninstalled imbalanced-learn-0.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall -y scikit-learn imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.4.0\n",
      "  Obtaining dependency information for scikit-learn==1.4.0 from https://files.pythonhosted.org/packages/a8/e9/3e4879974a7c4dcaca2a746dde3df08d0ae8f14c74b03591616ce5f0a8b1/scikit_learn-1.4.0-1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached scikit_learn-1.4.0-1-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\prita\\anaconda3\\lib\\site-packages (from scikit-learn==1.4.0) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\prita\\anaconda3\\lib\\site-packages (from scikit-learn==1.4.0) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\prita\\anaconda3\\lib\\site-packages (from scikit-learn==1.4.0) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\prita\\anaconda3\\lib\\site-packages (from scikit-learn==1.4.0) (3.6.0)\n",
      "Using cached scikit_learn-1.4.0-1-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Obtaining dependency information for imbalanced-learn from https://files.pythonhosted.org/packages/c7/b5/56f1ceb568676c0231d12b2fed17ebfd606dd1f627e7372aaed5dd56bd97/imbalanced_learn-0.14.1-py3-none-any.whl.metadata\n",
      "  Using cached imbalanced_learn-0.14.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.25.2 in c:\\users\\prita\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.11.4 in c:\\users\\prita\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.17.0)\n",
      "Collecting scikit-learn<2,>=1.4.2 (from imbalanced-learn)\n",
      "  Obtaining dependency information for scikit-learn<2,>=1.4.2 from https://files.pythonhosted.org/packages/89/3c/45c352094cfa60050bcbb967b1faf246b22e93cb459f2f907b600f2ceda5/scikit_learn-1.8.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached scikit_learn-1.8.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: sklearn-compat<0.2,>=0.1.5 in c:\\users\\prita\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.1.5)\n",
      "Requirement already satisfied: joblib<2,>=1.2.0 in c:\\users\\prita\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\prita\\anaconda3\\lib\\site-packages (from imbalanced-learn) (3.6.0)\n",
      "Using cached imbalanced_learn-0.14.1-py3-none-any.whl (235 kB)\n",
      "Using cached scikit_learn-1.8.0-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "Installing collected packages: scikit-learn, imbalanced-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.4.0\n",
      "    Uninstalling scikit-learn-1.4.0:\n",
      "      Successfully uninstalled scikit-learn-1.4.0\n",
      "Successfully installed imbalanced-learn-0.14.1 scikit-learn-1.8.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install xg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading https://files.pythonhosted.org/packages/24/14/d9ecb9fa86727f51bfb35f1c2b0428ebc6cd5ffde24c5e2dc583d3575a6f/xgboost-1.6.2-py3-none-win_amd64.whl (125.4MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\brainware university\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\brainware university\\anaconda3\\lib\\site-packages (from xgboost) (1.21.6)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.6.2\n",
      "1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'AI_Data_CSE_final.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Class Average: 78.32%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average of all semester marks for each student\n",
    "semester_cols = ['Marks_sem1 ', 'Marks_sem2', 'Marks_sem3', 'Marks_sem4',\n",
    "                 'Marks_sem5', 'Marks_sem6', 'Marks_sem7', 'Marks_sem8']\n",
    "df['Aggregate_Marks'] = df[semester_cols].mean(axis=1)\n",
    "# Calculate the Global Average (Mean of the entire class)\n",
    "global_average = df['Aggregate_Marks'].mean()\n",
    "print(f\"Global Class Average: {global_average:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Student Segments Count:\n",
      "Moderate    128\n",
      "Slow         84\n",
      "Advance       7\n",
      "Name: Learner_Segment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the classification function\n",
    "def classify_learner(score):\n",
    "    if score >= 90:\n",
    "        return 'Advance'\n",
    "    elif score < global_average:\n",
    "        return 'Slow'\n",
    "    else:\n",
    "        return 'Moderate'\n",
    "# Apply the classification\n",
    "df['Learner_Segment'] = df['Aggregate_Marks'].apply(classify_learner)\n",
    "\n",
    "# Check the distribution of segments\n",
    "print(\"\\nStudent Segments Count:\")\n",
    "print(df['Learner_Segment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Prepare Data for Random Forest\n",
    "# We select features that might predict the learner type (excluding the marks used to derive the label)\n",
    "# Using features like previous academic history, attendance, skills, etc.\n",
    "feature_columns = ['Marks_sem1 ', 'Marks_sem2', 'Marks_sem3', 'Marks_sem4',\n",
    "                 'Marks_sem5', 'Marks_sem6', 'Marks_sem7', 'Marks_sem8']\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df['Learner_Segment']\n",
    "\n",
    "# Handle any missing values (filling with mean for simplicity)\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Encode the target labels (Slow, Moderate, Advance) into numbers\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BRAINWARE UNIVERSITY\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6287: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Advance       1.00      1.00      1.00        25\n",
      "    Moderate       0.97      1.00      0.98        28\n",
      "        Slow       1.00      0.93      0.97        15\n",
      "\n",
      "    accuracy                           0.99        68\n",
      "   macro avg       0.99      0.98      0.98        68\n",
      "weighted avg       0.99      0.99      0.99        68\n",
      "\n",
      "Saved: learner_model.pkl, updated_with_learnerType.csv\n"
     ]
    }
   ],
   "source": [
    "X = df[feature_columns]\n",
    "X.fillna(X.median(), inplace=True)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df['Learner_Segment'])\n",
    "\n",
    "# Adjust k_neighbors for SMOTE to be less than the number of minority samples (which is 5 for 'Advanced')\n",
    "smote = SMOTE(sampling_strategy='minority', k_neighbors=4)\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "X_n = minmax.fit_transform(X_sm)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_n, y_sm, test_size=0.2, random_state=16)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# --- Metrics & report ---\n",
    "pred = clf.predict(X_test)\n",
    "print(\"Classification report:\\n\", classification_report(y_test, pred, target_names=le.classes_))\n",
    "\n",
    "# --- Save model (pickle) ---\n",
    "with open('Student_Grading_Model.pkl', 'wb') as f:\n",
    "    pickle.dump({'model': clf, 'label_encoder': le}, f)\n",
    "\n",
    "# --- Save updated dataset with LearnerType ---\n",
    "df.to_csv('updated_with_learnerType.csv', index=False)\n",
    "print(\"Saved: learner_model.pkl, updated_with_learnerType.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
